"""
–ú–æ–¥—É–ª—å –¥–ª—è –≤—ã–±–æ—Ä–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤

–ú–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –°–æ–∑–¥–∞–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤—ã–±–æ—Ä–æ–∫
- –ê–Ω–∞–ª–∏–∑–∞ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—ã–±–æ—Ä–æ–∫
- –†–∞—Å—á–µ—Ç–∞ —Ä–∞–∑–º–µ—Ä–∞ –≤—ã–±–æ—Ä–∫–∏
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
- –ü—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Å–∏–º—É–ª—è—Ü–∏–π –≤—ã–±–æ—Ä–æ—á–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import t, norm
import warnings
import os
from typing import Union, Tuple, List, Dict, Optional

warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ matplotlib –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
plt.rcParams['font.size'] = 12
plt.rcParams['figure.figsize'] = (10, 6)

def load_population(filename: str = 'customer_population.csv') -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞–ª—å–Ω—É—é —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –∏–∑ CSV —Ñ–∞–π–ª–∞
    
    Parameters:
    -----------
    filename : str
        –ò–º—è —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'customer_population.csv')
    
    Returns:
    --------
    pd.DataFrame or None
        DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É
        possible_paths = [
            filename,
            f'files/{filename}',
            f'./{filename}',
            f'../files/{filename}'
        ]
        
        df = None
        for path in possible_paths:
            if os.path.exists(path):
                df = pd.read_csv(path, sep=';', encoding='utf-8')
                print(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {path}")
                break
        
        if df is None:
            print(f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –ø—É—Ç–µ–π:")
            for path in possible_paths:
                print(f"   - {path}")
            return None
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏
        expected_columns = ['customer_id', 'age', 'annual_spend', 'satisfaction', 'city', 'is_premium', 'gender']
        missing_columns = set(expected_columns) - set(df.columns)
        
        if missing_columns:
            print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã {missing_columns}")
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üìã –°—Ç–æ–ª–±—Ü—ã: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ {filename}: {str(e)}")
        return None

def create_random_sample(population: pd.DataFrame, size: int, seed: int = 42) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ—Å—Ç—É—é —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
    
    Parameters:
    -----------
    population : pd.DataFrame
        –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å
    size : int
        –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    seed : int
        –°–µ–º—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        
    Returns:
    --------
    pd.DataFrame
        –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
    """
    if size > len(population):
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ ({size}) –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ–ø—É–ª—è—Ü–∏–∏ ({len(population)})")
        print(f"–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ä–∞–≤–Ω—ã–º —Ä–∞–∑–º–µ—Ä—É –ø–æ–ø—É–ª—è—Ü–∏–∏")
        size = len(population)
    
    np.random.seed(seed)
    sample = population.sample(n=size, random_state=seed).reset_index(drop=True)
    
    print(f"üé≤ –°–æ–∑–¥–∞–Ω–∞ —Å–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–º {len(sample)} –∏–∑ {len(population)} –∑–∞–ø–∏—Å–µ–π")
    return sample

def create_stratified_sample(population: pd.DataFrame, strata_column: str, size: int, 
                           proportional: bool = True, seed: int = 42) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É
    
    Parameters:
    -----------
    population : pd.DataFrame
        –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å
    strata_column : str
        –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'city')
    size : int
        –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    proportional : bool
        –ï—Å–ª–∏ True, —Ç–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
        –ï—Å–ª–∏ False, —Ç–æ —Ä–∞–≤–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å—Ç—Ä–∞—Ç
    seed : int
        –°–µ–º—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        
    Returns:
    --------
    pd.DataFrame
        –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
    """
    np.random.seed(seed)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞—Ç–∞—Ö
    strata_info = population[strata_column].value_counts()
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç—Ä–∞—Ç–∞–º ({strata_column}):")
    for stratum, count in strata_info.items():
        percentage = (count / len(population)) * 100
        print(f"   {stratum}: {count} ({percentage:.1f}%)")
    
    stratified_sample = pd.DataFrame()
    
    if proportional:
        # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è
        proportions = population[strata_column].value_counts(normalize=True)
        
        for stratum, proportion in proportions.items():
            stratum_data = population[population[strata_column] == stratum]
            stratum_size = int(size * proportion)
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–∞—Ç—ã (—á—Ç–æ–±—ã —Å—É–º–º–∞ –±—ã–ª–∞ —Ä–∞–≤–Ω–∞ size)
            if stratum == proportions.index[-1]:
                current_total = len(stratified_sample)
                stratum_size = size - current_total
            
            if stratum_size > 0 and len(stratum_data) > 0:
                actual_size = min(stratum_size, len(stratum_data))
                stratum_sample = stratum_data.sample(n=actual_size, random_state=seed+hash(stratum)%1000)
                stratified_sample = pd.concat([stratified_sample, stratum_sample])
                print(f"   {stratum}: –æ—Ç–æ–±—Ä–∞–Ω–æ {actual_size} –∏–∑ {len(stratum_data)}")
    else:
        # –†–∞–≤–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å—Ç—Ä–∞—Ç
        size_per_stratum = size // len(strata_info)
        remainder = size % len(strata_info)
        
        for i, (stratum, count) in enumerate(strata_info.items()):
            stratum_data = population[population[strata_column] == stratum]
            stratum_size = size_per_stratum + (1 if i < remainder else 0)
            
            if len(stratum_data) > 0:
                actual_size = min(stratum_size, len(stratum_data))
                stratum_sample = stratum_data.sample(n=actual_size, random_state=seed+i)
                stratified_sample = pd.concat([stratified_sample, stratum_sample])
                print(f"   {stratum}: –æ—Ç–æ–±—Ä–∞–Ω–æ {actual_size} –∏–∑ {len(stratum_data)}")
    
    stratified_sample = stratified_sample.reset_index(drop=True)
    print(f"üèó –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–º {len(stratified_sample)}")
    
    return stratified_sample

def create_systematic_sample(population: pd.DataFrame, size: int, seed: int = 42) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –≤—ã–±–æ—Ä–∫—É
    
    Parameters:
    -----------
    population : pd.DataFrame
        –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å
    size : int
        –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    seed : int
        –°–µ–º—è –¥–ª—è –≤—ã–±–æ—Ä–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞
        
    Returns:
    --------
    pd.DataFrame
        –°–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤—ã–±–æ—Ä–∫–∞
    """
    N = len(population)
    
    if size >= N:
        print(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª—å—à–µ –∏–ª–∏ —Ä–∞–≤–µ–Ω —Ä–∞–∑–º–µ—Ä—É –ø–æ–ø—É–ª—è—Ü–∏–∏")
        return population.copy()
    
    # –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤—ã–±–æ—Ä–∫–∏
    k = N // size
    
    # –°–ª—É—á–∞–π–Ω—ã–π —Å—Ç–∞—Ä—Ç
    np.random.seed(seed)
    start = np.random.randint(0, k)
    
    # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –≤—ã–±–æ—Ä–∫–∏
    indices = [start + i * k for i in range(size) if start + i * k < N]
    
    # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑ –Ω–∞—á–∞–ª–∞
    while len(indices) < size and len(indices) < N:
        additional_indices = [i for i in range(N) if i not in indices]
        indices.extend(additional_indices[:size - len(indices)])
    
    systematic_sample = population.iloc[indices].reset_index(drop=True)
    
    print(f"üìä –°–æ–∑–¥–∞–Ω–∞ —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤—ã–±–æ—Ä–∫–∞:")
    print(f"   –†–∞–∑–º–µ—Ä –ø–æ–ø—É–ª—è—Ü–∏–∏: {N}")
    print(f"   –ò–Ω—Ç–µ—Ä–≤–∞–ª –≤—ã–±–æ—Ä–∫–∏ (k): {k}")
    print(f"   –°–ª—É—á–∞–π–Ω—ã–π —Å—Ç–∞—Ä—Ç: {start}")
    print(f"   –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {len(systematic_sample)}")
    
    return systematic_sample

def calculate_sample_statistics(sample: pd.DataFrame, 
                               variables: Optional[List[str]] = None) -> Dict[str, Dict[str, float]]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–±–æ—Ä–∫–∏
    
    Parameters:
    -----------
    sample : pd.DataFrame
        –í—ã–±–æ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    variables : list, optional
        –°–ø–∏—Å–æ–∫ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–µ—Å–ª–∏ None, —Ç–æ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ)
        
    Returns:
    --------
    dict
        –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    """
    if variables is None:
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        numeric_cols = sample.select_dtypes(include=[np.number]).columns.tolist()
    else:
        numeric_cols = [col for col in variables if col in sample.columns and 
                       sample[col].dtype in ['int64', 'float64']]
    
    stats_dict = {}
    
    for col in numeric_cols:
        if sample[col].notna().sum() > 0:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –Ω–µ-NaN –∑–Ω–∞—á–µ–Ω–∏—è
            stats_dict[col] = {
                'count': int(sample[col].count()),
                'mean': float(sample[col].mean()),
                'std': float(sample[col].std()),
                'min': float(sample[col].min()),
                'max': float(sample[col].max()),
                'median': float(sample[col].median()),
                'q25': float(sample[col].quantile(0.25)),
                'q75': float(sample[col].quantile(0.75))
            }
    
    # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    categorical_cols = sample.select_dtypes(include=['object', 'category']).columns.tolist()
    
    for col in categorical_cols:
        if col not in stats_dict:
            value_counts = sample[col].value_counts()
            proportions = sample[col].value_counts(normalize=True)
            
            stats_dict[col] = {
                'count': int(sample[col].count()),
                'unique_values': int(sample[col].nunique()),
                'most_frequent': str(value_counts.index[0]) if len(value_counts) > 0 else None,
                'most_frequent_count': int(value_counts.iloc[0]) if len(value_counts) > 0 else 0,
                'most_frequent_prop': float(proportions.iloc[0]) if len(proportions) > 0 else 0.0
            }
    
    return stats_dict

def confidence_interval_mean(data: Union[pd.Series, np.ndarray, List], 
                           confidence: float = 0.95) -> Tuple[float, Tuple[float, float]]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ
    
    Parameters:
    -----------
    data : array-like
        –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    confidence : float
        –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.95)
        
    Returns:
    --------
    tuple
        (—Å—Ä–µ–¥–Ω–µ–µ, (–Ω–∏–∂–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞, –≤–µ—Ä—Ö–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞))
    """
    data = np.array(data)
    data = data[~np.isnan(data)]  # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
    
    if len(data) == 0:
        raise ValueError("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    
    n = len(data)
    mean = np.mean(data)
    std_err = stats.sem(data)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º t-—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –º–∞–ª—ã—Ö –≤—ã–±–æ—Ä–æ–∫ –∏–ª–∏ –∫–æ–≥–¥–∞ œÉ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ
    alpha = 1 - confidence
    t_critical = stats.t.ppf(1 - alpha/2, df=n-1)
    
    # –ì—Ä–∞–Ω–∏—Ü—ã –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    margin_error = t_critical * std_err
    ci_lower = mean - margin_error
    ci_upper = mean + margin_error
    
    return mean, (ci_lower, ci_upper)

def confidence_interval_proportion(successes: int, n: int, 
                                 confidence: float = 0.95) -> Tuple[float, Tuple[float, float]]:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –¥–æ–ª–∏
    
    Parameters:
    -----------
    successes : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—Ö–æ–≤
    n : int
        –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    confidence : float
        –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è
        
    Returns:
    --------
    tuple
        (–¥–æ–ª—è, (–Ω–∏–∂–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞, –≤–µ—Ä—Ö–Ω—è—è_–≥—Ä–∞–Ω–∏—Ü–∞))
    """
    if n <= 0:
        raise ValueError("–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º")
    
    if successes < 0 or successes > n:
        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—Å–ø–µ—Ö–æ–≤ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ—Ç 0 –¥–æ n")
    
    p = successes / n
    alpha = 1 - confidence
    z_critical = stats.norm.ppf(1 - alpha/2)
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–æ–ª–∏
    std_err = np.sqrt(p * (1 - p) / n)
    
    # –ì—Ä–∞–Ω–∏—Ü—ã –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
    margin_error = z_critical * std_err
    ci_lower = max(0, p - margin_error)
    ci_upper = min(1, p + margin_error)
    
    return p, (ci_lower, ci_upper)

def sample_size_for_mean(z: float, sigma: float, error: float) -> int:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ
    
    Parameters:
    -----------
    z : float
        z-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1.96 –¥–ª—è 95%)
    sigma : float
        –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø–æ–ø—É–ª—è—Ü–∏–∏ (–∏–ª–∏ –µ–≥–æ –æ—Ü–µ–Ω–∫–∞)
    error : float
        –î–æ–ø—É—Å—Ç–∏–º–∞—è –æ—à–∏–±–∫–∞
        
    Returns:
    --------
    int
        –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    """
    if z <= 0 or sigma <= 0 or error <= 0:
        raise ValueError("–í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏")
    
    n = ((z * sigma) / error) ** 2
    return int(np.ceil(n))

def sample_size_for_proportion(z: float, p: float, error: float) -> int:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–æ–ª–∏
    
    Parameters:
    -----------
    z : float
        z-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    p : float
        –û–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è (–µ—Å–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ 0.5)
    error : float
        –î–æ–ø—É—Å—Ç–∏–º–∞—è –æ—à–∏–±–∫–∞
        
    Returns:
    --------
    int
        –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏
    """
    if z <= 0 or error <= 0:
        raise ValueError("z –∏ error –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏")
    
    if p < 0 or p > 1:
        raise ValueError("–î–æ–ª—è p –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Ç 0 –¥–æ 1")
    
    n = (z ** 2 * p * (1 - p)) / (error ** 2)
    return int(np.ceil(n))

def compare_sampling_methods(population: pd.DataFrame, size: int = 500, 
                           strata_column: str = 'city') -> pd.DataFrame:
    """
    –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã –≤—ã–±–æ—Ä–∫–∏
    
    Parameters:
    -----------
    population : pd.DataFrame
        –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å
    size : int
        –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    strata_column : str
        –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        
    Returns:
    --------
    pd.DataFrame
        –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    # –ò—Å—Ç–∏–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–ø—É–ª—è—Ü–∏–∏
    numeric_vars = population.select_dtypes(include=[np.number]).columns
    true_params = {}
    
    for var in numeric_vars:
        if var != 'customer_id':  # –ò—Å–∫–ª—é—á–∞–µ–º ID
            true_params[var] = {
                'mean': population[var].mean(),
                'std': population[var].std()
            }
    
    # –°–æ–∑–¥–∞–µ–º –≤—ã–±–æ—Ä–∫–∏ —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
    try:
        random_sample = create_random_sample(population, size, seed=42)
        stratified_sample = create_stratified_sample(population, strata_column, size, seed=42)
        systematic_sample = create_systematic_sample(population, size, seed=42)
        
        samples = {
            'Random': random_sample,
            'Stratified': stratified_sample, 
            'Systematic': systematic_sample
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        
        for method_name, sample in samples.items():
            for var in true_params.keys():
                if var in sample.columns:
                    sample_mean = sample[var].mean()
                    sample_std = sample[var].std()
                    true_mean = true_params[var]['mean']
                    
                    bias = sample_mean - true_mean
                    relative_bias = (bias / true_mean) * 100 if true_mean != 0 else 0
                    
                    results.append({
                        'Method': method_name,
                        'Variable': var,
                        'True_Mean': round(true_mean, 2),
                        'Sample_Mean': round(sample_mean, 2),
                        'Bias': round(bias, 2),
                        'Relative_Bias_%': round(relative_bias, 2),
                        'Sample_Std': round(sample_std, 2),
                        'Sample_Size': len(sample)
                    })
        
        comparison_df = pd.DataFrame(results)
        
        print("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –≤—ã–±–æ—Ä–∫–∏:")
        print("="*60)
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —á—Ç–µ–Ω–∏—è
        for var in true_params.keys():
            if var in comparison_df['Variable'].values:
                print(f"\nüìà {var.upper()}:")
                var_data = comparison_df[comparison_df['Variable'] == var]
                for _, row in var_data.iterrows():
                    print(f"  {row['Method']:12} | –°–º–µ—â–µ–Ω–∏–µ: {row['Bias']:>6.1f} | "
                          f"–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ: {row['Relative_Bias_%']:>5.1f}%")
        
        return comparison_df
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –º–µ—Ç–æ–¥–æ–≤: {str(e)}")
        return pd.DataFrame()

def simulate_confidence_intervals(population: pd.DataFrame, column: str, 
                                n_simulations: int = 100, sample_size: int = 200, 
                                confidence: float = 0.95) -> Dict:
    """
    –°–∏–º—É–ª–∏—Ä—É–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    
    Parameters:
    -----------
    population : pd.DataFrame
        –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å
    column : str
        –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    n_simulations : int
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π
    sample_size : int
        –†–∞–∑–º–µ—Ä –∫–∞–∂–¥–æ–π –≤—ã–±–æ—Ä–∫–∏
    confidence : float
        –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è
        
    Returns:
    --------
    dict
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–π
    """
    if column not in population.columns:
        raise ValueError(f"–ö–æ–ª–æ–Ω–∫–∞ '{column}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
    
    true_mean = population[column].mean()
    results = []
    
    print(f"üî¨ –ó–∞–ø—É—Å–∫ —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:")
    print(f"   –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {column}")
    print(f"   –ò—Å—Ç–∏–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: {true_mean:.2f}")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º—É–ª—è—Ü–∏–π: {n_simulations}")
    print(f"   –†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏: {sample_size}")
    print(f"   –£—Ä–æ–≤–µ–Ω—å –¥–æ–≤–µ—Ä–∏—è: {confidence:.0%}")
    
    for i in range(n_simulations):
        # –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
        sample = population[column].sample(n=sample_size, replace=False, random_state=i+42)
        
        # –°—Ç—Ä–æ–∏–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
        try:
            mean, (ci_lower, ci_upper) = confidence_interval_mean(sample, confidence)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            contains_true = ci_lower <= true_mean <= ci_upper
            
            results.append({
                'simulation': i+1,
                'sample_mean': mean,
                'ci_lower': ci_lower,
                'ci_upper': ci_upper,
                'ci_width': ci_upper - ci_lower,
                'contains_true': contains_true
            })
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Å–∏–º—É–ª—è—Ü–∏–∏ {i+1}: {str(e)}")
            continue
    
    if not results:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –Ω–∏ –æ–¥–Ω–æ–π —É—Å–ø–µ—à–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏")
        return {}
    
    results_df = pd.DataFrame(results)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
    coverage = results_df['contains_true'].mean()
    mean_width = results_df['ci_width'].mean()
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏:")
    print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤: {coverage:.1%}")
    print(f"   –û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ: {confidence:.1%}")
    print(f"   –°—Ä–µ–¥–Ω—è—è —à–∏—Ä–∏–Ω–∞ –î–ò: {mean_width:.2f}")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö —Å–∏–º—É–ª—è—Ü–∏–π: {len(results_df)} –∏–∑ {n_simulations}")
    
    return {
        'results': results_df,
        'true_mean': true_mean,
        'coverage': coverage,
        'expected_coverage': confidence,
        'mean_width': mean_width
    }

def plot_confidence_intervals_simulation(simulation_results: Dict, max_intervals: int = 50):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤
    
    Parameters:
    -----------
    simulation_results : dict
        –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∏–º—É–ª—è—Ü–∏–∏ –∏–∑ —Ñ—É–Ω–∫—Ü–∏–∏ simulate_confidence_intervals
    max_intervals : int
        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    """
    if 'results' not in simulation_results:
        print("‚ùå –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏")
        return
    
    results_df = simulation_results['results']
    true_mean = simulation_results['true_mean']
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    plot_data = results_df.head(max_intervals).copy()
    
    # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ–∏–∫
    fig, ax = plt.subplots(figsize=(12, 8))
    
    for i, (_, row) in enumerate(plot_data.iterrows()):
        # –¶–≤–µ—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        color = 'blue' if row['contains_true'] else 'red'
        alpha = 0.7 if row['contains_true'] else 1.0
        linewidth = 1 if row['contains_true'] else 2
        
        # –†–∏—Å—É–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª
        ax.plot([row['ci_lower'], row['ci_upper']], [i, i], 
               color=color, alpha=alpha, linewidth=linewidth)
        
        # –†–∏—Å—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—ã–±–æ—Ä–∫–∏
        ax.plot(row['sample_mean'], i, 'o', color=color, alpha=alpha, markersize=3)
    
    # –ò—Å—Ç–∏–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
    ax.axvline(true_mean, color='green', linestyle='--', linewidth=2,
              label=f'–ò—Å—Ç–∏–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: {true_mean:.2f}')
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –ª–µ–≥–µ–Ω–¥—ã
    n_correct = plot_data['contains_true'].sum()
    n_total = len(plot_data)
    coverage_rate = n_correct / n_total
    
    ax.set_xlabel('–ó–Ω–∞—á–µ–Ω–∏–µ')
    ax.set_ylabel('–ù–æ–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏')
    ax.set_title(f'–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è {n_total} –≤—ã–±–æ—Ä–æ–∫\n'
                f'–ü–æ–∫—Ä—ã—Ç–∏–µ: {n_correct}/{n_total} ({coverage_rate:.1%})')
    
    # –°–æ–∑–¥–∞–µ–º –ª–µ–≥–µ–Ω–¥—É
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], color='green', linestyle='--', linewidth=2, label=f'–ò—Å—Ç–∏–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ: {true_mean:.2f}'),
        Line2D([0], [0], color='blue', linewidth=1, label=f'–°–æ–¥–µ—Ä–∂–∞—Ç –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {n_correct}'),
        Line2D([0], [0], color='red', linewidth=2, label=f'–ù–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {n_total - n_correct}')
    ]
    ax.legend(handles=legend_elements, loc='upper right')
    
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    print(f"üìä –ü–æ–∫–∞–∑–∞–Ω–æ {len(plot_data)} –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –∏–∑ {len(results_df)} –æ–±—â–∏—Ö")

def analyze_sample_representativeness(sample: pd.DataFrame, population: pd.DataFrame, 
                                    key_variables: List[str]) -> pd.DataFrame:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º
    
    Parameters:
    -----------
    sample : pd.DataFrame
        –î–∞–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏
    population : pd.DataFrame
        –î–∞–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏
    key_variables : list
        –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        
    Returns:
    --------
    pd.DataFrame
        –¢–∞–±–ª–∏—Ü–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    """
    results = []
    
    for var in key_variables:
        if var not in sample.columns or var not in population.columns:
            print(f"‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{var}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö")
            continue
        
        if sample[var].dtype in ['int64', 'float64']:
            # –î–ª—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            pop_mean = population[var].mean()
            sample_mean = sample[var].mean()
            bias = sample_mean - pop_mean
            relative_bias = (bias / pop_mean) * 100 if pop_mean != 0 else 0
            
            # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –≤—ã–±–æ—Ä–æ—á–Ω–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
            try:
                _, (ci_lower, ci_upper) = confidence_interval_mean(sample[var])
                contains_true = ci_lower <= pop_mean <= ci_upper
            except:
                ci_lower = ci_upper = np.nan
                contains_true = False
            
            results.append({
                'Variable': var,
                'Type': 'Numeric',
                'Population_Value': round(pop_mean, 3),
                'Sample_Value': round(sample_mean, 3),
                'Bias': round(bias, 3),
                'Relative_Bias_%': round(relative_bias, 2),
                'CI_Lower': round(ci_lower, 3),
                'CI_Upper': round(ci_upper, 3),
                'Contains_True': contains_true
            })
            
        else:
            # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            pop_dist = population[var].value_counts(normalize=True).sort_index()
            sample_dist = sample[var].value_counts(normalize=True).sort_index()
            
            for category in pop_dist.index:
                pop_prop = pop_dist.get(category, 0)
                sample_prop = sample_dist.get(category, 0)
                bias = sample_prop - pop_prop
                relative_bias = (bias / pop_prop) * 100 if pop_prop > 0 else 0
                
                # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –¥–æ–ª–∏
                try:
                    n_successes = int(sample_prop * len(sample))
                    _, (ci_lower, ci_upper) = confidence_interval_proportion(n_successes, len(sample))
                    contains_true = ci_lower <= pop_prop <= ci_upper
                except:
                    ci_lower = ci_upper = np.nan
                    contains_true = False
                
                results.append({
                    'Variable': f"{var}_{category}",
                    'Type': 'Categorical',
                    'Population_Value': round(pop_prop, 3),
                    'Sample_Value': round(sample_prop, 3),
                    'Bias': round(bias, 3),
                    'Relative_Bias_%': round(relative_bias, 2),
                    'CI_Lower': round(ci_lower, 3),
                    'CI_Upper': round(ci_upper, 3),
                    'Contains_True': contains_true
                })
    
    analysis_df = pd.DataFrame(results)
    
    if len(analysis_df) > 0:
        print("üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—ã–±–æ—Ä–∫–∏:")
        print("="*80)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        for var_type in ['Numeric', 'Categorical']:
            type_data = analysis_df[analysis_df['Type'] == var_type]
            if len(type_data) > 0:
                print(f"\nüìà {var_type} –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:")
                for _, row in type_data.iterrows():
                    status = "‚úÖ" if row['Contains_True'] else "‚ùå"
                    print(f"  {status} {row['Variable']:20} | "
                          f"–°–º–µ—â–µ–Ω–∏–µ: {row['Relative_Bias_%']:>6.1f}% | "
                          f"–î–ò –ø–æ–∫—Ä—ã–≤–∞–µ—Ç: {row['Contains_True']}")
    
    return analysis_df

# –§—É–Ω–∫—Ü–∏–∏-–ø–æ–º–æ—â–Ω–∏–∫–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
def get_z_critical(confidence: float) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç z-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–æ–≤–µ—Ä–∏—è"""
    alpha = 1 - confidence
    return stats.norm.ppf(1 - alpha/2)

def get_t_critical(confidence: float, df: int) -> float:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç t-–∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–æ–≤–µ—Ä–∏—è –∏ —Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã"""
    alpha = 1 - confidence
    return stats.t.ppf(1 - alpha/2, df)

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–æ–¥—É–ª—è
if __name__ == "__main__":
    print("üöÄ –ú–æ–¥—É–ª—å –¥–ª—è –≤—ã–±–æ—Ä–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω!")
    print("\nüìö –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
    print("="*50)
    
    functions = [
        "load_population() - –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
        "create_random_sample() - —Å–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞", 
        "create_stratified_sample() - —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞",
        "create_systematic_sample() - —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≤—ã–±–æ—Ä–∫–∞",
        "calculate_sample_statistics() - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–±–æ—Ä–∫–∏",
        "confidence_interval_mean() - –î–ò –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ",
        "confidence_interval_proportion() - –î–ò –¥–ª—è –¥–æ–ª–∏",
        "sample_size_for_mean() - —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è —Å—Ä–µ–¥–Ω–µ–≥–æ",
        "sample_size_for_proportion() - —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–æ–ª–∏",
        "compare_sampling_methods() - —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –≤—ã–±–æ—Ä–∫–∏",  
        "simulate_confidence_intervals() - —Å–∏–º—É–ª—è—Ü–∏—è –î–ò",
        "analyze_sample_representativeness() - –∞–Ω–∞–ª–∏–∑ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏"
    ]
    
    for func in functions:
        print(f"  üìù {func}")
    
    print(f"\nüí° –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:")
    print("="*30)
    print("population = load_population()")
    print("sample = create_random_sample(population, 500)")
    print("mean, ci = confidence_interval_mean(sample['annual_spend'])")
    print("print(f'–°—Ä–µ–¥–Ω–µ–µ: {mean:.0f}, –î–ò: [{ci[0]:.0f}; {ci[1]:.0f}]')")
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    try:
        population = load_population()
        if population is not None:
            print(f"\n‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–∞!")
            print(f"üìä –†–∞–∑–º–µ—Ä –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏: {len(population)}")
            
            # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
            sample = create_random_sample(population, 100, seed=42)
            stats_dict = calculate_sample_statistics(sample)
            
            print(f"\nüìà –ü—Ä–∏–º–µ—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –≤—ã–±–æ—Ä–∫–∏ (n=100):")
            for var, stats in stats_dict.items():
                if isinstance(stats, dict) and 'mean' in stats:
                    print(f"  {var}: —Å—Ä–µ–¥–Ω–µ–µ = {stats['mean']:.1f}, œÉ = {stats['std']:.1f}")
                    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏: {str(e)}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª customer_population.csv –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ files/")