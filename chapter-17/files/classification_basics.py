"""
üéØ –û—Å–Ω–æ–≤—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç:
- –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é, –¥–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π, —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
- –ü—Ä–∞–≤–∏–ª—å–Ω—É—é –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
- –û—Ü–µ–Ω–∫—É –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–∞–Ω–∏—Ü —Ä–µ—à–µ–Ω–∏–π
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                           f1_score, confusion_matrix, classification_report,
                           roc_curve, roc_auc_score, precision_recall_curve)
import warnings

warnings.filterwarnings('ignore')

print("üéØ –ò–∑—É—á–∞–µ–º –æ—Å–Ω–æ–≤—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏!")
print("=" * 60)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10
sns.set_style("whitegrid")

def generate_sample_data():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    np.random.seed(42)
    n_customers = 1000
    
    print("üîß –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞...")
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç—è–º–∏
    data = {}
    
    # –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    data['age'] = np.random.normal(35, 12, n_customers).astype(int)
    data['age'] = np.clip(data['age'], 18, 70)
    
    data['income'] = np.random.lognormal(11, 0.5, n_customers)  # log-normal —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    data['income'] = np.clip(data['income'], 20000, 500000)
    
    data['gender'] = np.random.choice(['M', 'F'], n_customers)
    
    # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–∑–∞–≤–∏—Å—è—Ç –æ—Ç –¥–µ–º–æ–≥—Ä–∞—Ñ–∏–∏)
    data['days_since_registration'] = np.random.exponential(180, n_customers).astype(int)
    data['total_sessions'] = np.random.poisson(data['age'] / 3, n_customers)
    data['avg_session_duration'] = np.random.exponential(15, n_customers)  # –º–∏–Ω—É—Ç—ã
    
    # –ü–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
    data['total_spent'] = (
        data['income'] * 0.001 * np.random.uniform(0.5, 1.5, n_customers) +
        data['total_sessions'] * np.random.uniform(100, 500, n_customers)
    )
    
    data['number_of_purchases'] = np.random.poisson(
        np.clip(data['total_sessions'] / 5, 0, 20), n_customers
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–æ–≥–∏—á–Ω—ã—Ö –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π
    purchase_probability = (
        0.1 +  # –±–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        (data['income'] - np.min(data['income'])) / (np.max(data['income']) - np.min(data['income'])) * 0.3 +  # –¥–æ—Ö–æ–¥
        (data['total_sessions'] / np.max(data['total_sessions'])) * 0.2 +  # –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        (data['total_spent'] / np.max(data['total_spent'])) * 0.3 +  # –∏—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞—Ç
        np.random.normal(0, 0.1, n_customers)  # —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å
    )
    
    purchase_probability = np.clip(purchase_probability, 0, 1)
    data['will_purchase'] = np.random.binomial(1, purchase_probability, n_customers)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
    df = pd.DataFrame(data)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    df['customer_type'] = pd.cut(df['total_spent'], 
                               bins=[0, 50000, 150000, np.inf], 
                               labels=['Bronze', 'Silver', 'Gold'])
    
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
    print(df['will_purchase'].value_counts())
    print(f"   –î–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤: {df['will_purchase'].mean():.1%}")
    
    return df

def explore_data(data):
    """–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîç –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö:")
    print("=" * 40)
    
    # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"üìè –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö: {data.shape}")
    print(f"üìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    print(data.dtypes)
    
    # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    missing = data.isnull().sum()
    if missing.sum() > 0:
        print(f"\n‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
        print(missing[missing > 0])
    else:
        print(f"\n‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç")
    
    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    numeric_columns = data.select_dtypes(include=[np.number]).columns
    correlations = data[numeric_columns].corr()['will_purchase'].abs().sort_values(ascending=False)
    
    print(f"\nüéØ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π:")
    for col, corr in correlations.items():
        if col != 'will_purchase':
            print(f"  {col}: {corr:.3f}")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    data['will_purchase'].value_counts().plot(kind='bar', ax=axes[0,0])
    axes[0,0].set_title('üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π')
    axes[0,0].set_xlabel('–ë—É–¥–µ—Ç –ø–æ–∫—É–ø–∞—Ç—å')
    axes[0,0].set_ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')
    
    # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
    sns.heatmap(data[numeric_columns].corr(), annot=True, cmap='coolwarm', 
                center=0, ax=axes[0,1])
    axes[0,1].set_title('üî• –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞')
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    data.boxplot(column='income', by='will_purchase', ax=axes[1,0])
    axes[1,0].set_title('üí∞ –î–æ—Ö–æ–¥ vs –ü–æ–∫—É–ø–∫–∏')
    axes[1,0].set_xlabel('–ë—É–¥–µ—Ç –ø–æ–∫—É–ø–∞—Ç—å')
    axes[1,0].set_ylabel('–î–æ—Ö–æ–¥')
    
    data.boxplot(column='total_spent', by='will_purchase', ax=axes[1,1])
    axes[1,1].set_title('üí≥ –ò—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞—Ç vs –ü–æ–∫—É–ø–∫–∏')
    axes[1,1].set_xlabel('–ë—É–¥–µ—Ç –ø–æ–∫—É–ø–∞—Ç—å')
    axes[1,1].set_ylabel('–ü–æ—Ç—Ä–∞—á–µ–Ω–æ —Ä–∞–Ω–µ–µ')
    
    plt.tight_layout()
    plt.show()

def prepare_data_for_ml(data):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
    print("\nüîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:")
    print("=" * 45)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö
    df = data.copy()
    
    # Feature engineering
    print("‚ú® –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    df['spending_rate'] = df['total_spent'] / (df['days_since_registration'] + 1)
    df['session_value'] = df['total_spent'] / (df['total_sessions'] + 1)
    df['purchase_frequency'] = df['number_of_purchases'] / (df['total_sessions'] + 1)
    df['high_income'] = (df['income'] > df['income'].median()).astype(int)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print("üè∑Ô∏è –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö...")
    le_gender = LabelEncoder()
    df['gender_encoded'] = le_gender.fit_transform(df['gender'])
    
    # One-hot encoding –¥–ª—è customer_type
    customer_type_dummies = pd.get_dummies(df['customer_type'], prefix='type')
    df = pd.concat([df, customer_type_dummies], axis=1)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
    feature_columns = [
        'age', 'income', 'days_since_registration', 'total_sessions',
        'avg_session_duration', 'total_spent', 'number_of_purchases',
        'spending_rate', 'session_value', 'purchase_frequency', 'high_income',
        'gender_encoded'
    ] + list(customer_type_dummies.columns)
    
    X = df[feature_columns]
    y = df['will_purchase']
    
    print(f"üìä –ò—Ç–æ–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–∏: {len(X.columns)}")
    print(f"   {list(X.columns)}")
    
    return X, y, feature_columns

def train_classification_models(X, y, feature_names):
    """–û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    print("\nü§ñ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print("=" * 40)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    print(f"  –î–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –≤ train: {y_train.mean():.1%}")
    print(f"  –î–æ–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –≤ test: {y_test.mean():.1%}")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (–Ω—É–∂–Ω–æ –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    models = {}
    results = {}
    
    # 1. –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
    print(f"\nüéØ –û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏...")
    log_reg = LogisticRegression(random_state=42, max_iter=1000)
    log_reg.fit(X_train_scaled, y_train)
    models['–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è'] = (log_reg, X_train_scaled, X_test_scaled)
    
    # 2. –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π
    print(f"üå≥ –û–±—É—á–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π...")
    tree = DecisionTreeClassifier(
        max_depth=10, 
        min_samples_split=20, 
        random_state=42
    )
    tree.fit(X_train, y_train)
    models['–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π'] = (tree, X_train, X_test)
    
    # 3. –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
    print(f"üå≤ –û–±—É—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞...")
    rf = RandomForestClassifier(
        n_estimators=100, 
        max_depth=15,
        min_samples_split=10,
        random_state=42,
        n_jobs=-1
    )
    rf.fit(X_train, y_train)
    models['–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å'] = (rf, X_train, X_test)
    
    # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
    print(f"\nüìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π:")
    print("-" * 80)
    print(f"{'–ú–æ–¥–µ–ª—å':<20} {'Accuracy':<10} {'Precision':<11} {'Recall':<8} {'F1':<8} {'AUC-ROC':<8}")
    print("-" * 80)
    
    for name, (model, X_tr, X_te) in models.items():
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(X_te)
        y_proba = model.predict_proba(X_te)[:, 1]
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        auc_roc = roc_auc_score(y_test, y_proba)
        
        results[name] = {
            'model': model,
            'y_pred': y_pred,
            'y_proba': y_proba,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'auc_roc': auc_roc
        }
        
        print(f"{name:<20} {accuracy:<10.3f} {precision:<11.3f} {recall:<8.3f} {f1:<8.3f} {auc_roc:<8.3f}")
    
    return models, results, X_train, X_test, y_train, y_test, scaler, feature_names

def visualize_model_results(models, results, X_test, y_test, feature_names):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π"""
    print(f"\nüé® –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π:")
    
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏', fontsize=16)
    
    # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    metrics_df = pd.DataFrame({
        name: [res['accuracy'], res['precision'], res['recall'], res['f1'], res['auc_roc']]
        for name, res in results.items()
    }, index=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC-ROC'])
    
    metrics_df.plot(kind='bar', ax=axes[0,0])
    axes[0,0].set_title('üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫')
    axes[0,0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏')
    axes[0,0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    axes[0,0].tick_params(axis='x', rotation=45)
    
    # 2. ROC-–∫—Ä–∏–≤—ã–µ
    for name, res in results.items():
        fpr, tpr, _ = roc_curve(y_test, res['y_proba'])
        axes[0,1].plot(fpr, tpr, label=f"{name} (AUC={res['auc_roc']:.3f})")
    
    axes[0,1].plot([0, 1], [0, 1], 'k--', label='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä')
    axes[0,1].set_xlabel('False Positive Rate')
    axes[0,1].set_ylabel('True Positive Rate')
    axes[0,1].set_title('üìà ROC-–∫—Ä–∏–≤—ã–µ')
    axes[0,1].legend()
    axes[0,1].grid(True, alpha=0.3)
    
    # 3. Precision-Recall –∫—Ä–∏–≤—ã–µ
    for name, res in results.items():
        precision, recall, _ = precision_recall_curve(y_test, res['y_proba'])
        axes[0,2].plot(recall, precision, label=f"{name}")
    
    axes[0,2].set_xlabel('Recall')
    axes[0,2].set_ylabel('Precision')
    axes[0,2].set_title('üéØ Precision-Recall –∫—Ä–∏–≤—ã–µ')
    axes[0,2].legend()
    axes[0,2].grid(True, alpha=0.3)
    
    # 4. Confusion matrices
    model_names = list(results.keys())
    for i, name in enumerate(model_names):
        if i >= 3:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3
            break
        
        cm = confusion_matrix(y_test, results[name]['y_pred'])
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1,i])
        axes[1,i].set_title(f'üîç –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫\n{name}')
        axes[1,i].set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ')
        axes[1,i].set_ylabel('–†–µ–∞–ª—å–Ω–æ')
    
    plt.tight_layout()
    plt.show()

def analyze_feature_importance(models, feature_names):
    """–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print(f"\nüéØ –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    print("=" * 35)
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
    log_reg_model = models['–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è'][0]
    coefficients = pd.DataFrame({
        'feature': feature_names,
        'coefficient': log_reg_model.coef_[0],
        'abs_coefficient': np.abs(log_reg_model.coef_[0])
    }).sort_values('abs_coefficient', ascending=True)
    
    coefficients.tail(10).plot(x='feature', y='coefficient', kind='barh', ax=axes[0])
    axes[0].set_title('üìä –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n(—Ç–æ–ø-10 –ø–æ –º–æ–¥—É–ª—é)')
    axes[0].set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç')
    
    # –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π - –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    tree_model = models['–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π'][0]
    tree_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': tree_model.feature_importances_
    }).sort_values('importance', ascending=True)
    
    tree_importance.tail(10).plot(x='feature', y='importance', kind='barh', ax=axes[1])
    axes[1].set_title('üå≥ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n(–¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π)')
    axes[1].set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
    
    # –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å - –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    rf_model = models['–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å'][0]
    rf_importance = pd.DataFrame({
        'feature': feature_names,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=True)
    
    rf_importance.tail(10).plot(x='feature', y='importance', kind='barh', ax=axes[2])
    axes[2].set_title('üå≤ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n(—Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å)')
    axes[2].set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')
    
    plt.tight_layout()
    plt.show()
    
    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    print(f"üèÜ –¢–æ–ø-5 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –º–æ–¥–µ–ª—è–º:")
    print(f"\nüìä –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (–ø–æ –º–æ–¥—É–ª—é –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞):")
    for _, row in coefficients.tail(5).iterrows():
        print(f"  {row['feature']}: {row['coefficient']:+.3f}")
    
    print(f"\nüå≥ –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π:")
    for _, row in tree_importance.tail(5).iterrows():
        print(f"  {row['feature']}: {row['importance']:.3f}")
    
    print(f"\nüå≤ –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å:")
    for _, row in rf_importance.tail(5).iterrows():
        print(f"  {row['feature']}: {row['importance']:.3f}")

def visualize_decision_tree(models, feature_names):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π"""
    print(f"\nüå≥ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π:")
    
    tree_model = models['–î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π'][0]
    
    plt.figure(figsize=(20, 12))
    plot_tree(tree_model, 
              feature_names=feature_names,
              class_names=['–ù–µ –∫—É–ø–∏—Ç', '–ö—É–ø–∏—Ç'],
              filled=True,
              rounded=True,
              fontsize=10,
              max_depth=3)  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Ä—Ö–Ω–∏–µ 3 —É—Ä–æ–≤–Ω—è
    plt.title('üå≥ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 3 —É—Ä–æ–≤–Ω—è)', fontsize=16)
    plt.show()

def cross_validation_analysis(models, X, y):
    """–ê–Ω–∞–ª–∏–∑ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    print(f"\nüîÑ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π:")
    print("=" * 30)
    
    cv_results = {}
    
    for name, (model, X_data, _) in models.items():
        if '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è' in name:
            # –î–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring='f1')
        else:
            cv_scores = cross_val_score(model, X, y, cv=5, scoring='f1')
        
        cv_results[name] = cv_scores
        
        print(f"{name}:")
        print(f"  F1-scores –ø–æ —Ñ–æ–ª–¥–∞–º: {cv_scores}")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ F1: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
        print(f"  –î–∏–∞–ø–∞–∑–æ–Ω: [{cv_scores.min():.3f}, {cv_scores.max():.3f}]")
        print()
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ CV
    plt.figure(figsize=(12, 6))
    cv_data = [scores for scores in cv_results.values()]
    plt.boxplot(cv_data, labels=list(cv_results.keys()))
    plt.title('üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ F1-score –ø–æ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏')
    plt.ylabel('F1-score')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def business_interpretation(results, models, feature_names):
    """–ë–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print(f"\nüíº –ë–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
    print("=" * 40)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ F1-score
    best_model_name = max(results.keys(), key=lambda x: results[x]['f1'])
    best_result = results[best_model_name]
    
    print(f"üèÜ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
    print(f"   F1-score: {best_result['f1']:.3f}")
    print(f"   –¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {best_result['accuracy']:.3f}")
    print(f"   Precision: {best_result['precision']:.3f}")
    print(f"   Recall: {best_result['recall']:.3f}")
    
    print(f"\nüí° –ë–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:")
    print(f"   ‚Ä¢ –ò–∑ 100 –∫–ª–∏–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π,")
    print(f"     —Ä–µ–∞–ª—å–Ω–æ –∫—É–ø—è—Ç {best_result['precision']*100:.0f} –∫–ª–∏–µ–Ω—Ç–æ–≤")
    print(f"   ‚Ä¢ –ú–æ–¥–µ–ª—å –Ω–∞–π–¥–µ—Ç {best_result['recall']*100:.0f}% –æ—Ç –≤—Å–µ—Ö –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π")
    print(f"   ‚Ä¢ –û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {best_result['accuracy']*100:.0f}%")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
    print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–π –∫–∞–º–ø–∞–Ω–∏–∏:")
    
    # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if '–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å' in best_model_name or '–î–µ—Ä–µ–≤–æ' in best_model_name:
        model = models[best_model_name][0]
        importance = pd.DataFrame({
            'feature': feature_names,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print(f"   üìä –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∫—É–ø–∫–∏ (–ø–æ {best_model_name}):")
        for _, row in importance.head(3).iterrows():
            feature = row['feature']
            imp = row['importance']
            print(f"   ‚Ä¢ {feature}: –≤–∞–∂–Ω–æ—Å—Ç—å {imp:.3f}")
    
    print(f"\nüí∞ –≠–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–π —ç—Ñ—Ñ–µ–∫—Ç:")
    print(f"   ‚Ä¢ –ü—Ä–∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞ 100 —Ä—É–±. –∏ —Å—Ä–µ–¥–Ω–µ–º —á–µ–∫–µ 5000 —Ä—É–±:")
    print(f"   ‚Ä¢ ROI –æ—Ç —Ç–∞—Ä–≥–µ—Ç–∏–Ω–≥–∞: {(best_result['precision'] * 5000 - 100) / 100 * 100:.0f}%")
    print(f"   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–≤—è–∑—ã–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö")
    print(f"     –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—É–ø–∫–∏ > {1 - best_result['precision']:.2f}")

def create_prediction_function(best_model, scaler, feature_names):
    """–°–æ–∑–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤"""
    print(f"\nüîÆ –°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    print("=" * 35)
    
    def predict_customer_purchase(customer_data):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—É–ø–∫–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
        
        customer_data: dict —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –∫–ª–∏–µ–Ω—Ç–∞
        """
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
        df = pd.DataFrame([customer_data])
        
        # Feature engineering (—Ç–µ –∂–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
        if 'spending_rate' not in df.columns:
            df['spending_rate'] = df['total_spent'] / (df['days_since_registration'] + 1)
        if 'session_value' not in df.columns:
            df['session_value'] = df['total_spent'] / (df['total_sessions'] + 1)
        if 'purchase_frequency' not in df.columns:
            df['purchase_frequency'] = df['number_of_purchases'] / (df['total_sessions'] + 1)
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        X_new = df[feature_names]
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        if scaler is not None:
            X_new_scaled = scaler.transform(X_new)
            probability = best_model.predict_proba(X_new_scaled)[0, 1]
        else:
            probability = best_model.predict_proba(X_new)[0, 1]
        
        return probability
    
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ñ—É–Ω–∫—Ü–∏–∏
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    
    test_customers = [
        {
            'age': 30, 'income': 80000, 'days_since_registration': 365,
            'total_sessions': 50, 'avg_session_duration': 20, 'total_spent': 25000,
            'number_of_purchases': 8, 'high_income': 1, 'gender_encoded': 1,
            'type_Bronze': 0, 'type_Silver': 1, 'type_Gold': 0
        },
        {
            'age': 55, 'income': 150000, 'days_since_registration': 180,
            'total_sessions': 120, 'avg_session_duration': 25, 'total_spent': 80000,
            'number_of_purchases': 15, 'high_income': 1, 'gender_encoded': 0,
            'type_Bronze': 0, 'type_Silver': 0, 'type_Gold': 1
        }
    ]
    
    for i, customer in enumerate(test_customers, 1):
        prob = predict_customer_purchase(customer)
        print(f"   –ö–ª–∏–µ–Ω—Ç {i}: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–∫—É–ø–∫–∏ = {prob:.1%}")
        recommendation = "–û—Ç–ø—Ä–∞–≤–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ" if prob > 0.5 else "–ù–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å"
        print(f"   –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {recommendation}")
        print()
    
    return predict_customer_purchase

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
    print("üöÄ –ó–∞–ø—É—Å–∫ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏!")
    
    # 1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ –∏—Å—Å–ª–µ–¥—É–µ–º –¥–∞–Ω–Ω—ã–µ
    data = generate_sample_data()
    explore_data(data)
    
    # 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML
    X, y, feature_names = prepare_data_for_ml(data)
    
    # 3. –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏
    models, results, X_train, X_test, y_train, y_test, scaler, _ = train_classification_models(X, y, feature_names)
    
    # 4. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    visualize_model_results(models, results, X_test, y_test, feature_names)
    
    # 5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    analyze_feature_importance(models, feature_names)
    
    # 6. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π
    visualize_decision_tree(models, feature_names)
    
    # 7. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cross_validation_analysis(models, X, y)
    
    # 8. –ë–∏–∑–Ω–µ—Å-–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    business_interpretation(results, models, feature_names)
    
    # 9. –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    best_model_name = max(results.keys(), key=lambda x: results[x]['f1'])
    best_model = models[best_model_name][0]
    best_scaler = scaler if '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è' in best_model_name else None
    
    predict_func = create_prediction_function(best_model, best_scaler, feature_names)
    
    print(f"\nüéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("üìö –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –∏–∑—É—á–∏—Ç–µ regression_models.py")
    print("üí° –°–æ–≤–µ—Ç: —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏ –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏!")
    
    return models, results, predict_func

if __name__ == "__main__":
    models, results, predict_function = main()