# ü§ñ –ì–ª–∞–≤–∞ 17: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏ —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å —É—á–∏—Ç–µ–ª–µ–º!

## üéØ –ß—Ç–æ –≤—ã –∏–∑—É—á–∏—Ç–µ

–ü–æ—Å–ª–µ –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–æ–π –≥–ª–∞–≤—ã –≤—ã —Å–º–æ–∂–µ—Ç–µ:

- üß† **–°—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- üìä **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, –¥–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π, —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å)
- üìà **–°–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏** –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Ü–µ–Ω, –ø—Ä–æ–¥–∞–∂, –¥–æ—Ö–æ–¥–æ–≤
- ‚öñÔ∏è **–û—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π** —Å –ø–æ–º–æ—â—å—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ (accuracy, F1, MSE, R¬≤)
- üéØ **–ù–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã** –∏ –∏–∑–±–µ–≥–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- üíº **–ü—Ä–∏–º–µ–Ω—è—Ç—å ML –≤ –±–∏–∑–Ω–µ—Å–µ** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π –∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤

## üåü –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏

**–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–µ –æ–±—É—á–µ–Ω–∏–µ** ‚Äî —ç—Ç–æ –∫–∞–∫ –æ–±—É—á–µ–Ω–∏–µ —Ä–µ–±–µ–Ω–∫–∞ –ø–æ —É—á–µ–±–Ω–∏–∫—É —Å –æ—Ç–≤–µ—Ç–∞–º–∏. –£ –Ω–∞—Å –µ—Å—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏, –∏ –º—ã —É—á–∏–º –∫–æ–º–ø—å—é—Ç–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç—å –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏.

### üé≠ **–ú–µ—Ç–∞—Ñ–æ—Ä–∞: –ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∫–∞–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —ç–∫–∑–∞–º–µ–Ω—É**

–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, —á—Ç–æ –≤—ã –≥–æ—Ç–æ–≤–∏—Ç–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ –∫ —ç–∫–∑–∞–º–µ–Ω—É:

- üìö **–û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ** ‚Äî —ç—Ç–æ —É—á–µ–±–Ω–∏–∫ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –æ—Ç–≤–µ—Ç–∞–º–∏
- üß† **–ú–æ–¥–µ–ª—å** ‚Äî —ç—Ç–æ —Å—Ç—É–¥–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —É—á–∏—Ç—Å—è
- üéØ **–ê–ª–≥–æ—Ä–∏—Ç–º** ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è (–∑—É–±—Ä–µ–∂–∫–∞, –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –ø—Ä–∞–∫—Ç–∏–∫–∞)
- üìù **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** ‚Äî —ç—Ç–æ –ø—Ä–æ–±–Ω—ã–π —ç–∫–∑–∞–º–µ–Ω –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–Ω–∞–Ω–∏–π
- ‚úÖ **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ** ‚Äî —ç—Ç–æ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–º —ç–∫–∑–∞–º–µ–Ω–µ
- üìä **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞** ‚Äî —ç—Ç–æ –æ—Ü–µ–Ω–∫–∞ –∑–∞ —ç–∫–∑–∞–º–µ–Ω

### üíº **–ó–∞—á–µ–º —ç—Ç–æ –Ω—É–∂–Ω–æ –∞–Ω–∞–ª–∏—Ç–∏–∫—É –≤ 2025:**

**–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**
```python
# –ë—É–¥–µ—Ç –ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–æ–∫—É–ø–∞—Ç—å? (–î–∞/–ù–µ—Ç)
# –ö–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ –ø—Ä–æ–¥–∞–µ—Ç—Å—è –ª—É—á—à–µ? (A/B/C)
# –Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ email —Å–ø–∞–º–æ–º? (–°–ø–∞–º/–ù–µ —Å–ø–∞–º)
```

**–†–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —á–∏—Å–ª–∞:**
```python
# –ö–∞–∫–∞—è –±—É–¥–µ—Ç —Ü–µ–Ω–∞ –Ω–∞ —Ç–æ–≤–∞—Ä –∑–∞–≤—Ç—Ä–∞?
# –°–∫–æ–ª—å–∫–æ –ø—Ä–æ–¥–∞–∂ –æ–∂–∏–¥–∞—Ç—å –≤ —Å–ª–µ–¥—É—é—â–µ–º –º–µ—Å—è—Ü–µ?
# –ö–∞–∫–æ–π –¥–æ—Ö–æ–¥ –ø—Ä–∏–Ω–µ—Å–µ—Ç –∫–ª–∏–µ–Ω—Ç –∑–∞ –≥–æ–¥?
```

## üß† –û—Å–Ω–æ–≤—ã –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

### üìä **–¢–∏–ø—ã –∑–∞–¥–∞—á –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**

#### üéØ **–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π**
- **–ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è:** –î–∞/–ù–µ—Ç, –°–ø–∞–º/–ù–µ —Å–ø–∞–º, –ö—É–ø–∏—Ç/–ù–µ –∫—É–ø–∏—Ç
- **–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è:** –ö–∞—Ç–µ–≥–æ—Ä–∏—è —Ç–æ–≤–∞—Ä–∞ (A/B/C/D), –°–µ–≥–º–µ–Ω—Ç –∫–ª–∏–µ–Ω—Ç–∞, –ò—Å—Ç–æ—á–Ω–∏–∫ —Ç—Ä–∞—Ñ–∏–∫–∞

#### üìà **–†–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π**
- **–¶–µ–Ω—ã:** –°—Ç–æ–∏–º–æ—Å—Ç—å –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, –∫—É—Ä—Å –∞–∫—Ü–∏–π
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–∞:** –ü—Ä–æ–¥–∞–∂–∏, –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏, –∫–æ–Ω–≤–µ—Ä—Å–∏—è
- **–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã:** –ü—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –±—É–¥—É—â–∏–µ –ø–µ—Ä–∏–æ–¥—ã

### üéì **–ü—Ä–æ—Ü–µ—Å—Å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**

```python
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
X = data[['–≤–æ–∑—Ä–∞—Å—Ç', '–¥–æ—Ö–æ–¥', '–ø–æ–ª']]  # –ü—Ä–∏–∑–Ω–∞–∫–∏ (features)
y = data['–∫—É–ø–∏—Ç_—Ç–æ–≤–∞—Ä']                # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (target)

# 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 3. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)

# 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
predictions = model.predict(X_test)

# 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, predictions)
print(f"–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {accuracy:.2%}")
```

## üéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π

### üßÆ **–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**

**–ü—Ä–∏–Ω—Ü–∏–ø:** –í–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–π –ª–∏–Ω–∏–∏ —Å—Ç—Ä–æ–∏–º S-–æ–±—Ä–∞–∑–Ω—É—é –∫—Ä–∏–≤—É—é (—Å–∏–≥–º–æ–∏–¥—É), –∫–æ—Ç–æ—Ä–∞—è –¥–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç 0 –¥–æ 1.

```python
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# –ü—Ä–∏–º–µ—Ä: –ë—É–¥–µ—Ç –ª–∏ –∫–ª–∏–µ–Ω—Ç –ø–æ–∫—É–ø–∞—Ç—å?
features = ['–≤–æ–∑—Ä–∞—Å—Ç', '–¥–æ—Ö–æ–¥', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ø–æ—Å–µ—â–µ–Ω–∏–π']
X = customers[features]
y = customers['–∫—É–ø–∏–ª_—Ç–æ–≤–∞—Ä']  # 0 –∏–ª–∏ 1

# –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train, y_train)

# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
probabilities = log_reg.predict_proba(X_test)[:, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ "1"
predictions = log_reg.predict(X_test)

print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_test, predictions):.2%}")
print("\n–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç:")
print(classification_report(y_test, predictions))
```

**‚öñÔ∏è –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üöÄ –ë—ã—Å—Ç—Ä–∞—è –∏ –ø—Ä–æ—Å—Ç–∞—è
- üìä –î–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å—ã  
- üîç –õ–µ–≥–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
- üìà –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª–∏–Ω–µ–π–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏

**‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- üìè –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç –ª–∏–Ω–µ–π–Ω—É—é —Å–≤—è–∑—å –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–æ–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è —à–∞–Ω—Å–æ–≤
- üö´ –ü–ª–æ—Ö–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Å–∏–ª—å–Ω–æ –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
- üìä –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–∞ –∫ –≤—ã–±—Ä–æ—Å–∞–º

### üå≥ **–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π ‚Äî –ø–æ–Ω—è—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞**

**–ü—Ä–∏–Ω—Ü–∏–ø:** –°—Ç—Ä–æ–∏–º –¥–µ—Ä–µ–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ "–µ—Å–ª–∏-—Ç–æ", –∫–∞–∫ –±–ª–æ–∫-—Å—Ö–µ–º—É –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π.

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

# –û–±—É—á–∞–µ–º –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π
tree = DecisionTreeClassifier(
    max_depth=5,        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞
    min_samples_split=20,  # –ú–∏–Ω–∏–º—É–º –æ–±—Ä–∞–∑—Ü–æ–≤ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è
    random_state=42
)

tree.fit(X_train, y_train)

# –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–µ—Ä–µ–≤–æ
plt.figure(figsize=(20, 10))
plot_tree(tree, feature_names=features, 
          class_names=['–ù–µ –∫—É–ø–∏—Ç', '–ö—É–ø–∏—Ç'],
          filled=True, rounded=True)
plt.title('üå≥ –î–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–∫—É–ø–æ–∫')
plt.show()

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
feature_importance = pd.DataFrame({
    'feature': features,
    'importance': tree.feature_importances_
}).sort_values('importance', ascending=False)

print("üéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
print(feature_importance)
```

**‚öñÔ∏è –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üß† –û—á–µ–Ω—å –ª–µ–≥–∫–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å
- üîß –ù–µ —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- üåø –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
- üìä –†–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö

**‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- üé≤ –°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
- üîÑ –ù–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (–º–∞–ª—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö ‚Üí —Ä–∞–∑–Ω—ã–µ –¥–µ—Ä–µ–≤—å—è)
- üìä –ú–æ–∂–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞

### üå≤ **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å ‚Äî –º—É–¥—Ä–æ—Å—Ç—å —Ç–æ–ª–ø—ã**

**–ü—Ä–∏–Ω—Ü–∏–ø:** –°—Ç—Ä–æ–∏–º –º–Ω–æ–≥–æ —Ä–∞–∑–Ω—ã—Ö –¥–µ—Ä–µ–≤—å–µ–≤ –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º –∏—Ö —Ä–µ—à–µ–Ω–∏—è. –ö–∞–∂–¥–æ–µ –¥–µ—Ä–µ–≤–æ –≤–∏–¥–∏—Ç —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

```python
from sklearn.ensemble import RandomForestClassifier

# –°–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
rf = RandomForestClassifier(
    n_estimators=100,     # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
    max_depth=10,         # –ì–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞
    min_samples_split=5,
    random_state=42,
    n_jobs=-1            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ —è–¥—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
)

rf.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
rf_predictions = rf.predict(X_test)
rf_probabilities = rf.predict_proba(X_test)[:, 1]

print("üå≤ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞:")
print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_test, rf_predictions):.2%}")

# –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–∞—è, —á–µ–º —É –æ–¥–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞)
feature_importance_rf = pd.DataFrame({
    'feature': features,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

print("\nüéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest):")
print(feature_importance_rf)
```

**‚öñÔ∏è –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üéØ –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
- üõ°Ô∏è –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é
- üìä –ù–∞–¥–µ–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- üîß –ú–∞–ª–æ —Ç—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

**‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- üì¶ –ú–µ–Ω–µ–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º, —á–µ–º –æ–¥–Ω–æ –¥–µ—Ä–µ–≤–æ
- üíª –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏
- üéØ –ú–æ–∂–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–∞—Ç—å—Å—è –Ω–∞ –æ—á–µ–Ω—å –∑–∞—à—É–º–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

## üìà –†–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–∏—Å–µ–ª

### üìè **–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –æ—Å–Ω–æ–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è**

**–ü—Ä–∏–Ω—Ü–∏–ø:** –ò—â–µ–º –ø—Ä—è–º—É—é –ª–∏–Ω–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –æ–±–ª–∞–∫–æ —Ç–æ—á–µ–∫.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# –ü—Ä–∏–º–µ—Ä: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
features = ['–ø–ª–æ—â–∞–¥—å', '—ç—Ç–∞–∂', '–≥–æ–¥_–ø–æ—Å—Ç—Ä–æ–π–∫–∏', '—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ_–¥–æ_—Ü–µ–Ω—Ç—Ä–∞']
X = houses[features]
y = houses['—Ü–µ–Ω–∞']

# –û–±—É—á–∞–µ–º –ª–∏–Ω–µ–π–Ω—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é
lin_reg = LinearRegression()
lin_reg.fit(X_train, y_train)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
predictions = lin_reg.predict(X_test)

# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
print(f"R¬≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏): {r2:.3f}")
print(f"–°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞: {mse:,.0f}")
print(f"–°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {np.mean(np.abs(y_test - predictions)):,.0f}")

# –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –º–æ–¥–µ–ª–∏
coefficients = pd.DataFrame({
    'feature': features,
    'coefficient': lin_reg.coef_,
    'abs_coefficient': np.abs(lin_reg.coef_)
}).sort_values('abs_coefficient', ascending=False)

print("\nüìä –í–ª–∏—è–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —Ü–µ–Ω—É:")
for _, row in coefficients.iterrows():
    print(f"  {row['feature']}: {row['coefficient']:+,.0f} —Ä—É–±.")
```

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤:**
- **–ü–ª–æ—â–∞–¥—å: +50,000** ‚Üí –∫–∞–∂–¥—ã–π –∫–≤.–º –¥–æ–±–∞–≤–ª—è–µ—Ç 50,000 —Ä—É–±–ª–µ–π –∫ —Ü–µ–Ω–µ
- **–≠—Ç–∞–∂: -2,000** ‚Üí –∫–∞–∂–¥—ã–π —ç—Ç–∞–∂ –≤—ã—à–µ —É–º–µ–Ω—å—à–∞–µ—Ç —Ü–µ–Ω—É –Ω–∞ 2,000 —Ä—É–±–ª–µ–π

### üåä **–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è ‚Äî –≥–∏–±–∫–∏–µ –∫—Ä–∏–≤—ã–µ**

**–ü—Ä–∏–Ω—Ü–∏–ø:** –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–∫ —Å—Ç–µ–ø–µ–Ω–∏ –∏—Å—Ö–æ–¥–Ω—ã—Ö (x¬≤, x¬≥) –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π.

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline

# –°–æ–∑–¥–∞–µ–º –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
poly_pipeline = Pipeline([
    ('poly', PolynomialFeatures(degree=2, include_bias=False)),
    ('linear', LinearRegression())
])

# –û–±—É—á–∞–µ–º
poly_pipeline.fit(X_train, y_train)
poly_predictions = poly_pipeline.predict(X_test)

# –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª—å—é
poly_r2 = r2_score(y_test, poly_predictions)
print(f"üìà –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è R¬≤: {r2:.3f}")
print(f"üåä –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è R¬≤: {poly_r2:.3f}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–¥–ª—è –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞)
if len(features) == 1:
    plt.figure(figsize=(12, 6))
    
    # –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    plt.scatter(X_test, y_test, alpha=0.6, label='–†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
    
    # –õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å
    plt.plot(X_test, predictions, 'r-', label='–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è')
    
    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
    sorted_idx = np.argsort(X_test.values.ravel())
    plt.plot(X_test.values.ravel()[sorted_idx], poly_predictions[sorted_idx], 
             'g-', label='–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è')
    
    plt.xlabel(features[0])
    plt.ylabel('–¶–µ–Ω–∞')
    plt.legend()
    plt.title('üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏')
    plt.show()
```

### üå≤ **–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏**

```python
from sklearn.ensemble import RandomForestRegressor

# Random Forest –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
rf_reg = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    random_state=42
)

rf_reg.fit(X_train, y_train)
rf_predictions = rf_reg.predict(X_test)

rf_r2 = r2_score(y_test, rf_predictions)
rf_mse = mean_squared_error(y_test, rf_predictions)

print(f"üå≤ Random Forest R¬≤: {rf_r2:.3f}")
print(f"üå≤ Random Forest MSE: {rf_mse:,.0f}")
```

## ‚öñÔ∏è –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π

### üìä **–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**

#### üéØ **–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏**

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
conf_matrix = confusion_matrix(y_test, predictions)
print("üîç –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
print(f"{'':>15} {'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ':>20}")
print(f"{'–†–µ–∞–ª—å–Ω–æ':>10} {'–ù–µ –∫—É–ø–∏—Ç':>10} {'–ö—É–ø–∏—Ç':>10}")
print(f"{'–ù–µ –∫—É–ø–∏—Ç':>10} {conf_matrix[0,0]:>10} {conf_matrix[0,1]:>10}")
print(f"{'–ö—É–ø–∏—Ç':>10} {conf_matrix[1,0]:>10} {conf_matrix[1,1]:>10}")

# –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
accuracy = accuracy_score(y_test, predictions)
precision = precision_score(y_test, predictions)
recall = recall_score(y_test, predictions)
f1 = f1_score(y_test, predictions)

print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
print(f"  üéØ Accuracy (—Ç–æ—á–Ω–æ—Å—Ç—å): {accuracy:.2%}")
print(f"  üîç Precision (—Ç–æ—á–Ω–æ—Å—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö): {precision:.2%}")
print(f"  üìà Recall (–ø–æ–ª–Ω–æ—Ç–∞): {recall:.2%}")
print(f"  ‚öñÔ∏è F1-score (–≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ): {f1:.2%}")
```

**–ö–æ–≥–¥–∞ —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**

- **üéØ Accuracy** ‚Äî –æ–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å, –∫–æ–≥–¥–∞ –∫–ª–∞—Å—Å—ã —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã
- **üîç Precision** ‚Äî –≤–∞–∂–Ω–æ –∏–∑–±–µ–∂–∞—Ç—å –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π (–∞–Ω—Ç–∏—Å–ø–∞–º, –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞)
- **üìà Recall** ‚Äî –≤–∞–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤—Å–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ (–ø–æ–∏—Å–∫ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞)
- **‚öñÔ∏è F1-score** ‚Äî –∫–æ–º–ø—Ä–æ–º–∏—Å—Å –º–µ–∂–¥—É precision –∏ recall

#### üìà **ROC-–∫—Ä–∏–≤–∞—è –∏ AUC**

```python
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤–º–µ—Å—Ç–æ –∫–ª–∞—Å—Å–æ–≤
y_proba = model.predict_proba(X_test)[:, 1]

# –°—Ç—Ä–æ–∏–º ROC-–∫—Ä–∏–≤—É—é
fpr, tpr, thresholds = roc_curve(y_test, y_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, 
         label=f'ROC –∫—Ä–∏–≤–∞—è (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('üìà ROC –ö—Ä–∏–≤–∞—è')
plt.legend(loc="lower right")
plt.show()

print(f"üìä AUC-ROC: {roc_auc:.3f}")
if roc_auc > 0.9:
    print("  üèÜ –û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ!")
elif roc_auc > 0.8:
    print("  ‚úÖ –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
elif roc_auc > 0.7:
    print("  üìä –ü—Ä–∏–µ–º–ª–µ–º–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ")
else:
    print("  ‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è")
```

### üìà **–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏**

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
mse = mean_squared_error(y_test, predictions)
mae = mean_absolute_error(y_test, predictions)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predictions)

print(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
print(f"  üìè R¬≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏): {r2:.3f}")
print(f"  üìä MSE (—Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞): {mse:,.0f}")
print(f"  üìà RMSE (–∫–æ—Ä–µ–Ω—å –∏–∑ MSE): {rmse:,.0f}")
print(f"  üìâ MAE (—Å—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞): {mae:,.0f}")

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è R¬≤
if r2 > 0.9:
    print("  üèÜ –û—Ç–ª–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å!")
elif r2 > 0.7:
    print("  ‚úÖ –•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å")
elif r2 > 0.5:
    print("  üìä –ü—Ä–∏–µ–º–ª–µ–º–∞—è –º–æ–¥–µ–ª—å")
else:
    print("  ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç –º–∞–ª–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π vs —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
plt.figure(figsize=(10, 8))
plt.scatter(y_test, predictions, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
plt.title(f'üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è vs –†–µ–∞–ª—å–Ω–æ—Å—Ç—å (R¬≤ = {r2:.3f})')
plt.show()
```

## üîÑ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### üìä **K-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è**

**–ü—Ä–æ–±–ª–µ–º–∞:** –ï—Å–ª–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å —Ç–æ–ª—å–∫–æ –Ω–∞ –æ–¥–Ω–æ–º —Ä–∞–∑–±–∏–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö, —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª—É—á–∞–π–Ω—ã–º.

**–†–µ—à–µ–Ω–∏–µ:** –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ K —á–∞—Å—Ç–µ–π, –æ–±—É—á–∞–µ–º—Å—è –Ω–∞ K-1 —á–∞—Å—Ç—è—Ö, —Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ—Å—Ç–∞–≤—à–µ–π—Å—è. –ü–æ–≤—Ç–æ—Ä—è–µ–º K —Ä–∞–∑.

```python
from sklearn.model_selection import cross_val_score, StratifiedKFold

# K-fold –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
cv_scores = cross_val_score(
    model, X, y, 
    cv=5,           # 5-fold
    scoring='accuracy'
)

print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –ø–æ —Ñ–æ–ª–¥–∞–º: {cv_scores}")
print(f"  –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
```

### üîß **–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤**

```python
from sklearn.model_selection import GridSearchCV

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ—Ç–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è Random Forest
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# –ü–æ–∏—Å–∫ –ø–æ —Å–µ—Ç–∫–µ —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=5,
    scoring='f1',
    n_jobs=-1,
    verbose=1
)

print("üîß –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
grid_search.fit(X_train, y_train)

print(f"‚úÖ –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {grid_search.best_params_}")
print(f"üìä –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ: {grid_search.best_score_:.3f}")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
best_model = grid_search.best_estimator_
```

## üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Feature Engineering)

### üîß **–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö**

```python
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
data = pd.DataFrame({
    '–≤–æ–∑—Ä–∞—Å—Ç': [25, 35, 45, 55],
    '–¥–æ—Ö–æ–¥': [30000, 80000, 120000, 60000],
    '–≥–æ—Ä–æ–¥': ['–ú–æ—Å–∫–≤–∞', '–°–ü–±', '–ú–æ—Å–∫–≤–∞', '–ö–∞–∑–∞–Ω—å'],
    '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ': ['–í—ã—Å—à–µ–µ', '–°—Ä–µ–¥–Ω–µ–µ', '–í—ã—Å—à–µ–µ', '–°—Ä–µ–¥–Ω–µ–µ']
})

# –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∏—Å–ª–æ–≤—ã–µ –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
numeric_features = ['–≤–æ–∑—Ä–∞—Å—Ç', '–¥–æ—Ö–æ–¥']
categorical_features = ['–≥–æ—Ä–æ–¥', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ']

# –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)
    ]
)

# –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', LogisticRegression())
])

# –¢–µ–ø–µ—Ä—å –º–æ–∂–µ–º –æ–±—É—á–∞—Ç—å —Å—Ä–∞–∑—É –Ω–∞ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
pipeline.fit(X_train, y_train)
predictions = pipeline.predict(X_test)
```

### üéØ **–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**

```python
def create_features(data):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"""
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    features = data.copy()
    
    # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    features['–¥–æ—Ö–æ–¥_–Ω–∞_–≤–æ–∑—Ä–∞—Å—Ç'] = features['–¥–æ—Ö–æ–¥'] / features['–≤–æ–∑—Ä–∞—Å—Ç']
    
    # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
    features['–≤–æ–∑—Ä–∞—Å—Ç–Ω–∞—è_–≥—Ä—É–ø–ø–∞'] = pd.cut(
        features['–≤–æ–∑—Ä–∞—Å—Ç'], 
        bins=[0, 30, 50, 100], 
        labels=['–ú–æ–ª–æ–¥—ã–µ', '–°—Ä–µ–¥–Ω–∏–µ', '–ó—Ä–µ–ª—ã–µ']
    )
    
    # –õ–æ–≥–∞—Ä–∏—Ñ–º—ã –¥–ª—è —Å–∫–æ—à–µ–Ω–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π
    features['log_–¥–æ—Ö–æ–¥'] = np.log1p(features['–¥–æ—Ö–æ–¥'])
    
    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —á–∏—Å–ª–æ–≤—ã—Ö
    features['–≤—ã—Å–æ–∫–∏–π_–¥–æ—Ö–æ–¥'] = (features['–¥–æ—Ö–æ–¥'] > features['–¥–æ—Ö–æ–¥'].median()).astype(int)
    
    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞—Ç—ã)
    if '–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏' in features.columns:
        features['–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = pd.to_datetime(features['–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'])
        features['–¥–Ω–∏_—Å_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = (datetime.now() - features['–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏']).dt.days
        features['–º–µ—Å—è—Ü_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = features['–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'].dt.month
        features['–¥–µ–Ω—å_–Ω–µ–¥–µ–ª–∏_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = features['–¥–∞—Ç–∞_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'].dt.dayofweek
    
    return features

# –ü—Ä–∏–º–µ–Ω—è–µ–º feature engineering
X_enhanced = create_features(X)
print(f"üéØ –°–æ–∑–¥–∞–Ω–æ {len(X_enhanced.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {len(X.columns)}")
```

## üíº –ë–∏–∑–Ω–µ—Å-–ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

### üõí **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è)**

```python
# –ú–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–∫—É–ø–æ–∫
def build_purchase_prediction_model(customer_data):
    """
    –°—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ–∫—É–ø–∫–∏
    """
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    features = [
        '–≤–æ–∑—Ä–∞—Å—Ç', '–¥–æ—Ö–æ–¥', '–ø–æ–ª_encoded', '–≥–æ—Ä–æ–¥_encoded',
        '–¥–Ω–∏_—Å_–ø–æ—Å–ª–µ–¥–Ω–µ–π_–ø–æ–∫—É–ø–∫–∏', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–ø—Ä–æ—à–ª—ã—Ö_–ø–æ–∫—É–ø–æ–∫',
        '—Å—Ä–µ–¥–Ω–∏–π_—á–µ–∫', '–ª—é–±–∏–º–∞—è_–∫–∞—Ç–µ–≥–æ—Ä–∏—è_encoded'
    ]
    
    X = customer_data[features]
    y = customer_data['–∫—É–ø–∏—Ç_–≤_—Å–ª–µ–¥—É—é—â–µ–º_–º–µ—Å—è—Ü–µ']
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)[:, 1]
    
    print("üõí –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–∫—É–ø–æ–∫:")
    print(f"  üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy_score(y_test, predictions):.2%}")
    print(f"  üìä F1-score: {f1_score(y_test, predictions):.3f}")
    
    # –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feature_importance = pd.DataFrame({
        'feature': features,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüéØ –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    for _, row in feature_importance.head().iterrows():
        print(f"  {row['feature']}: {row['importance']:.3f}")
    
    return model, feature_importance

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
def create_marketing_campaign(model, customers, campaign_budget=100000):
    """
    –°–æ–∑–¥–∞–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—É—é –∫–∞–º–ø–∞–Ω–∏—é
    """
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ–∫—É–ø–∫–∏
    probabilities = model.predict_proba(customers[features])[:, 1]
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫ –¥–∞–Ω–Ω—ã–º –∫–ª–∏–µ–Ω—Ç–æ–≤
    customers_with_proba = customers.copy()
    customers_with_proba['–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_–ø–æ–∫—É–ø–∫–∏'] = probabilities
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
    customers_with_proba = customers_with_proba.sort_values('–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_–ø–æ–∫—É–ø–∫–∏', ascending=False)
    
    # –†–∞—Å—á–µ—Ç ROI –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞
    customers_with_proba['–æ–∂–∏–¥–∞–µ–º–∞—è_–ø—Ä–∏–±—ã–ª—å'] = (
        customers_with_proba['–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_–ø–æ–∫—É–ø–∫–∏'] * 
        customers_with_proba['—Å—Ä–µ–¥–Ω–∏–π_—á–µ–∫'] * 0.2  # 20% –º–∞—Ä–∂–∞
    )
    
    # –°—Ç–æ–∏–º–æ—Å—Ç—å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–∞–∫—Ç–∞
    cost_per_contact = 50
    customers_with_proba['roi'] = (
        customers_with_proba['–æ–∂–∏–¥–∞–µ–º–∞—è_–ø—Ä–∏–±—ã–ª—å'] / cost_per_contact
    )
    
    # –í—ã–±–∏—Ä–∞–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤ —Å ROI > 1
    profitable_customers = customers_with_proba[customers_with_proba['roi'] > 1]
    
    # –£—á–∏—Ç—ã–≤–∞–µ–º –±—é–¥–∂–µ—Ç
    num_contacts = min(len(profitable_customers), campaign_budget // cost_per_contact)
    campaign_customers = profitable_customers.head(num_contacts)
    
    print(f"üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∫–∞–º–ø–∞–Ω–∏–∏:")
    print(f"  üéØ –°–≤—è–∑–∞—Ç—å—Å—è —Å {num_contacts:,} –∫–ª–∏–µ–Ω—Ç–∞–º–∏")
    print(f"  üí∞ –ë—é–¥–∂–µ—Ç: {num_contacts * cost_per_contact:,} —Ä—É–±.")
    print(f"  üìä –û–∂–∏–¥–∞–µ–º—ã–π –¥–æ—Ö–æ–¥: {campaign_customers['–æ–∂–∏–¥–∞–µ–º–∞—è_–ø—Ä–∏–±—ã–ª—å'].sum():,.0f} —Ä—É–±.")
    print(f"  üöÄ –û–∂–∏–¥–∞–µ–º—ã–π ROI: {campaign_customers['–æ–∂–∏–¥–∞–µ–º–∞—è_–ø—Ä–∏–±—ã–ª—å'].sum() / (num_contacts * cost_per_contact):.1f}x")
    
    return campaign_customers
```

### üìà **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è)**

```python
def build_sales_forecasting_model(sales_data):
    """
    –°—Ç—Ä–æ–∏—Ç –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥–∞–∂
    """
    
    # Feature engineering –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    sales_data['–¥–∞—Ç–∞'] = pd.to_datetime(sales_data['–¥–∞—Ç–∞'])
    sales_data['–≥–æ–¥'] = sales_data['–¥–∞—Ç–∞'].dt.year
    sales_data['–º–µ—Å—è—Ü'] = sales_data['–¥–∞—Ç–∞'].dt.month
    sales_data['–¥–µ–Ω—å_–Ω–µ–¥–µ–ª–∏'] = sales_data['–¥–∞—Ç–∞'].dt.dayofweek
    sales_data['–∫–≤–∞—Ä—Ç–∞–ª'] = sales_data['–¥–∞—Ç–∞'].dt.quarter
    sales_data['–¥–µ–Ω—å_–≥–æ–¥–∞'] = sales_data['–¥–∞—Ç–∞'].dt.dayofyear
    
    # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ –¥–ª—è —Ç—Ä–µ–Ω–¥–∞
    sales_data['–ø—Ä–æ–¥–∞–∂–∏_7–¥–Ω–µ–π'] = sales_data['–ø—Ä–æ–¥–∞–∂–∏'].rolling(7).mean()
    sales_data['–ø—Ä–æ–¥–∞–∂–∏_30–¥–Ω–µ–π'] = sales_data['–ø—Ä–æ–¥–∞–∂–∏'].rolling(30).mean()
    
    # –õ–∞–≥–∏ (–ø—Ä–æ–¥–∞–∂–∏ –≤ –ø—Ä–æ—à–ª—ã–µ –ø–µ—Ä–∏–æ–¥—ã)
    sales_data['–ø—Ä–æ–¥–∞–∂–∏_–≤—á–µ—Ä–∞'] = sales_data['–ø—Ä–æ–¥–∞–∂–∏'].shift(1)
    sales_data['–ø—Ä–æ–¥–∞–∂–∏_–Ω–µ–¥–µ–ª—é_–Ω–∞–∑–∞–¥'] = sales_data['–ø—Ä–æ–¥–∞–∂–∏'].shift(7)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ª–∞–≥–æ–≤
    sales_data = sales_data.dropna()
    
    features = [
        '–º–µ—Å—è—Ü', '–¥–µ–Ω—å_–Ω–µ–¥–µ–ª–∏', '–∫–≤–∞—Ä—Ç–∞–ª', '–¥–µ–Ω—å_–≥–æ–¥–∞',
        '–ø—Ä–æ–¥–∞–∂–∏_7–¥–Ω–µ–π', '–ø—Ä–æ–¥–∞–∂–∏_30–¥–Ω–µ–π', 
        '–ø—Ä–æ–¥–∞–∂–∏_–≤—á–µ—Ä–∞', '–ø—Ä–æ–¥–∞–∂–∏_–Ω–µ–¥–µ–ª—é_–Ω–∞–∑–∞–¥',
        '—Ü–µ–Ω–∞', '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ_—Ä–∞—Å—Ö–æ–¥—ã', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_–∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤'
    ]
    
    X = sales_data[features]
    y = sales_data['–ø—Ä–æ–¥–∞–∂–∏']
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–≤–∞–∂–Ω–æ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤!)
    split_date = sales_data['–¥–∞—Ç–∞'].quantile(0.8)
    train_mask = sales_data['–¥–∞—Ç–∞'] <= split_date
    
    X_train, X_test = X[train_mask], X[~train_mask]
    y_train, y_test = y[train_mask], y[~train_mask]
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = model.predict(X_test)
    
    # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    r2 = r2_score(y_test, predictions)
    mae = mean_absolute_error(y_test, predictions)
    
    print("üìà –ú–æ–¥–µ–ª—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–¥–∞–∂:")
    print(f"  üìä R¬≤ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {r2:.3f}")
    print(f"  üìè –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {mae:,.0f} –µ–¥–∏–Ω–∏—Ü")
    print(f"  üìà –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤ %: {(mae / y_test.mean()) * 100:.1f}%")
    
    return model, features
```

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –∏ —á–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏

### ‚ùå **–ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏ –Ω–æ–≤–∏—á–∫–æ–≤:**

1. **üîç –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö (Data Leakage)**
   ```python
   # ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—É–¥—É—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
   data['—Å—Ä–µ–¥–Ω–∏–π_—á–µ–∫_–∑–∞_–≥–æ–¥'] = data.groupby('–∫–ª–∏–µ–Ω—Ç_id')['—á–µ–∫'].transform('mean')
   
   # ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
   data['—Å—Ä–µ–¥–Ω–∏–π_—á–µ–∫_–¥–æ_–¥–∞—Ç—ã'] = data.groupby('–∫–ª–∏–µ–Ω—Ç_id')['—á–µ–∫'].expanding().mean()
   ```

2. **üìä –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**
   ```python
   # ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ - –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
   train_test_split(X, y, test_size=0.2, random_state=42)
   
   # ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ - —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
   split_date = data['–¥–∞—Ç–∞'].quantile(0.8)
   train_data = data[data['–¥–∞—Ç–∞'] <= split_date]
   test_data = data[data['–¥–∞—Ç–∞'] > split_date]
   ```

3. **üéØ –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤**
   ```python
   # ‚ùå –ï—Å–ª–∏ 95% –∫–ª–∏–µ–Ω—Ç–æ–≤ –Ω–µ –ø–æ–∫—É–ø–∞—é—Ç, accuracy = 95% –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞—á–∏—Ç
   print(f"Accuracy: {accuracy_score(y_test, predictions)}")
   
   # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º F1-score –∏–ª–∏ AUC-ROC
   print(f"F1-score: {f1_score(y_test, predictions)}")
   print(f"AUC-ROC: {roc_auc_score(y_test, probabilities)}")
   ```

### üí° **–õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**

1. **üîç –í—Å–µ–≥–¥–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º**
2. **üìä –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π –æ—Ü–µ–Ω–∫–∏**
3. **üéØ –í—ã–±–∏—Ä–∞–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á–µ–π**
4. **üîß –°–æ–∑–¥–∞–≤–∞–π—Ç–µ pipeline –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏**
5. **üìà –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –≤ production**
6. **üíº –í—Å–µ–≥–¥–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –±–∏–∑–Ω–µ—Å-—Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è**

## üöÄ –ì–æ—Ç–æ–≤—ã–µ —à–∞–±–ª–æ–Ω—ã –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è

### üéØ **–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏**

```python
def classification_pipeline(data, target_column, test_size=0.2):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import classification_report, confusion_matrix
    from sklearn.model_selection import cross_val_score
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = data.drop(columns=[target_column])
    y = data[target_column]
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42, stratify=y
    )
    
    # –ú–æ–¥–µ–ª—å
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    
    # –û–±—É—á–µ–Ω–∏–µ
    model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = model.predict(X_test)
    probabilities = model.predict_proba(X_test)[:, 1]
    
    # –û—Ü–µ–Ω–∫–∞
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    print(classification_report(y_test, predictions))
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
    cv_scores = cross_val_score(model, X, y, cv=5, scoring='f1')
    print(f"\nüîÑ –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è F1: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
    
    return model, X_test, y_test, predictions, probabilities

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
model, X_test, y_test, pred, proba = classification_pipeline(data, '–∫—É–ø–∏—Ç_—Ç–æ–≤–∞—Ä')
```

### üìà **–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Ä–µ–≥—Ä–µ—Å—Å–∏–∏**

```python
def regression_pipeline(data, target_column, test_size=0.2):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
    """
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    X = data.drop(columns=[target_column])
    y = data[target_column]
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=42
    )
    
    # –ú–æ–¥–µ–ª—å
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    
    # –û–±—É—á–µ–Ω–∏–µ
    model.fit(X_train, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    predictions = model.predict(X_test)
    
    # –û—Ü–µ–Ω–∫–∞
    r2 = r2_score(y_test, predictions)
    mse = mean_squared_error(y_test, predictions)
    mae = mean_absolute_error(y_test, predictions)
    
    print("üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:")
    print(f"  R¬≤ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç: {r2:.3f}")
    print(f"  MSE: {mse:,.0f}")
    print(f"  MAE: {mae:,.0f}")
    print(f"  RMSE: {np.sqrt(mse):,.0f}")
    
    return model, X_test, y_test, predictions

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ  
model, X_test, y_test, predictions = regression_pipeline(data, '—Ü–µ–Ω–∞')
```

## üöÄ –ß—Ç–æ –¥–∞–ª—å—à–µ?

–ü–æ—Å–ª–µ –æ—Å–≤–æ–µ–Ω–∏—è —ç—Ç–æ–π –≥–ª–∞–≤—ã –≤—ã —É–º–µ–µ—Ç–µ:

‚úÖ **–°—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π  
‚úÖ **–°–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏** –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π  
‚úÖ **–û—Ü–µ–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π** —Å –ø–æ–º–æ—â—å—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫  
‚úÖ **–ò–∑–±–µ–≥–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** —Å –ø–æ–º–æ—â—å—é –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏  
‚úÖ **–ü—Ä–∏–º–µ–Ω—è—Ç—å ML –≤ –±–∏–∑–Ω–µ—Å–µ** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ä–µ—à–µ–Ω–∏–π

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ò–∑—É—á–∏—Ç—å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ deep learning!

## üõ† –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏

–¢–µ–ø–µ—Ä—å –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç–µ –∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏—è–º ‚Äî –≤–∞—Å –∂–¥—É—Ç 5 –ø—Ä–æ–µ–∫—Ç–æ–≤ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —Ä–µ–∞–ª—å–Ω—ã—Ö ML-–º–æ–¥–µ–ª–µ–π:

- üìù [–ü–µ—Ä–µ–π—Ç–∏ –∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏—è–º](practice.md)
- ‚úÖ [–ü–µ—Ä–µ–π—Ç–∏ –∫ —á–µ–∫-–ª–∏—Å—Ç—É](checklist.md)
- üìÅ [–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —É—á–µ–±–Ω—ã–µ —Ñ–∞–π–ª—ã](files/README.md)

---

- üîô [–ü—Ä–µ–¥—ã–¥—É—â–∞—è –≥–ª–∞–≤–∞: –ì–ª–∞–≤–∞ 16 - –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è](../chapter-16/README.md)
- üîú [–°–ª–µ–¥—É—é—â–∞—è –≥–ª–∞–≤–∞: –ì–ª–∞–≤–∞ 18 - –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è](../chapter-18/README.md)

---

- üì¢ –ü—Ä–∏—Å–æ–µ–¥–∏–Ω—è–π—Ç–µ—Å—å –∫ —á–∞—Ç—É –∫—É—Ä—Å–∞: https://t.me/analytics_course_chat
- üì¢ –ö–∞–Ω–∞–ª –∫—É—Ä—Å–∞: https://t.me/analytics_course_channel